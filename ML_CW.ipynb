{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HRashmika/Bank_Prediction/blob/main/ML_CW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZz5aUWV3KHu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import os\n",
        "from imblearn.over_sampling import SMOTE\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# File path\n",
        "file_path = 'bank-additional-full.csv'\n",
        "data_add = pd.read_csv(file_path, delimiter=';')\n",
        "\n",
        "# Debugging: print the original data\n",
        "print(\"Original DataFrame:\")\n",
        "print(data_add.head())\n",
        "\n",
        "# Drop the 'duration' column as it's highly correlated with the target variable\n",
        "data_add = data_add.drop('duration', axis=1, errors='ignore')\n",
        "\n",
        "one_hot_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week']\n",
        "data_add = pd.get_dummies(data_add, columns=one_hot_columns, drop_first=True)\n",
        "\n",
        "label_columns = ['poutcome']\n",
        "label_encoder = LabelEncoder()\n",
        "label_mappings = {}\n",
        "\n",
        "for col in label_columns:\n",
        "    data_add[col] = label_encoder.fit_transform(data_add[col].fillna('unknown'))  # Fill NaNs with 'unknown'\n",
        "    label_mappings[col] = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "\n",
        "# Encode 'y' column as 1 for 'yes' and 0 for 'no'\n",
        "data_add['y'] = data_add['y'].map({'yes': 1, 'no': 0})\n",
        "\n",
        "# Print label mappings for reference\n",
        "print(\"\\nLabel Mappings:\")\n",
        "for col, mapping in label_mappings.items():\n",
        "    print(f\"{col}: {mapping}\")\n",
        "\n",
        "# Check and handle duplicates\n",
        "duplicates = data_add[data_add.duplicated()]\n",
        "if not duplicates.empty:\n",
        "    print(\"\\nDuplicate Rows Found:\")\n",
        "    print(duplicates)\n",
        "    data_add = data_add.drop_duplicates()\n",
        "    print(\"\\nDuplicates removed. Current shape of DataFrame:\", data_add.shape)\n",
        "else:\n",
        "    print(\"\\nNo duplicate rows found.\")\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = data_add.isnull().sum()\n",
        "if missing_values.any():\n",
        "    print(\"\\nMissing Values Found:\")\n",
        "    print(missing_values[missing_values > 0])\n",
        "    for col in data_add.columns:\n",
        "        if data_add[col].dtype == 'object':\n",
        "            data_add[col].fillna('unknown', inplace=True)\n",
        "        else:\n",
        "            data_add[col].fillna(data_add[col].median(), inplace=True)\n",
        "else:\n",
        "    print(\"\\nNo missing values found.\")\n",
        "\n",
        "# Min-Max Normalization\n",
        "scaler = MinMaxScaler()\n",
        "features_to_scale = data_add.drop('y', axis=1)\n",
        "data_add[features_to_scale.columns] = scaler.fit_transform(features_to_scale)\n",
        "X = data_add.drop('y', axis=1)\n",
        "y = data_add['y']\n",
        "\n",
        "# Perform train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "# Combine X and y for training and testing datasets\n",
        "train_data_add = pd.DataFrame(X_train_balanced, columns=X.columns)\n",
        "train_data_add['y'] = y_train_balanced\n",
        "\n",
        "test_data_add = X_test.copy()\n",
        "test_data_add['y'] = y_test\n",
        "\n",
        "# Print dataset shapes\n",
        "print(\"\\nTraining Data Shape (After Balancing):\", train_data_add.shape)\n",
        "print(\"Testing Data Shape:\", test_data_add.shape)\n",
        "print(\"\\nClass Distribution in Balanced Training Data:\")\n",
        "print(train_data_add['y'].value_counts(normalize=True))\n",
        "print(\"\\nFinal DataFrame Info:\")\n",
        "data_add.info()\n",
        "print(\"\\nFinal DataFrame Preview:\")\n",
        "print(data_add.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efsQjCUFXYHN",
        "outputId": "1d636034-4326-4086-a7ba-44284fbdcffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "   age        job  marital    education  default housing loan    contact  \\\n",
            "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
            "1   57   services  married  high.school  unknown      no   no  telephone   \n",
            "2   37   services  married  high.school       no     yes   no  telephone   \n",
            "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
            "4   56   services  married  high.school       no      no  yes  telephone   \n",
            "\n",
            "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
            "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "\n",
            "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
            "0          93.994          -36.4      4.857       5191.0  no  \n",
            "1          93.994          -36.4      4.857       5191.0  no  \n",
            "2          93.994          -36.4      4.857       5191.0  no  \n",
            "3          93.994          -36.4      4.857       5191.0  no  \n",
            "4          93.994          -36.4      4.857       5191.0  no  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "\n",
            "Label Mappings:\n",
            "poutcome: {'failure': 0, 'nonexistent': 1, 'success': 2}\n",
            "\n",
            "Duplicate Rows Found:\n",
            "       age  campaign  pdays  previous  poutcome  emp.var.rate  cons.price.idx  \\\n",
            "10      41         1    999         0         1           1.1          93.994   \n",
            "11      25         1    999         0         1           1.1          93.994   \n",
            "16      35         1    999         0         1           1.1          93.994   \n",
            "31      59         1    999         0         1           1.1          93.994   \n",
            "104     52         1    999         0         1           1.1          93.994   \n",
            "...    ...       ...    ...       ...       ...           ...             ...   \n",
            "39985   27         2    999         0         1          -1.7          94.055   \n",
            "40401   31         2    999         0         1          -1.7          94.027   \n",
            "40404   41         1    999         0         1          -1.7          94.027   \n",
            "40806   35         1    999         2         0          -1.1          94.199   \n",
            "40840   32         4    999         0         1          -1.1          94.199   \n",
            "\n",
            "       cons.conf.idx  euribor3m  nr.employed  ...  month_jun  month_mar  \\\n",
            "10             -36.4      4.857       5191.0  ...      False      False   \n",
            "11             -36.4      4.857       5191.0  ...      False      False   \n",
            "16             -36.4      4.857       5191.0  ...      False      False   \n",
            "31             -36.4      4.857       5191.0  ...      False      False   \n",
            "104            -36.4      4.857       5191.0  ...      False      False   \n",
            "...              ...        ...          ...  ...        ...        ...   \n",
            "39985          -39.8      0.761       4991.6  ...       True      False   \n",
            "40401          -38.3      0.904       4991.6  ...      False      False   \n",
            "40404          -38.3      0.904       4991.6  ...      False      False   \n",
            "40806          -37.5      0.878       4963.6  ...      False      False   \n",
            "40840          -37.5      0.879       4963.6  ...      False      False   \n",
            "\n",
            "       month_may  month_nov  month_oct  month_sep  day_of_week_mon  \\\n",
            "10          True      False      False      False             True   \n",
            "11          True      False      False      False             True   \n",
            "16          True      False      False      False             True   \n",
            "31          True      False      False      False             True   \n",
            "104         True      False      False      False             True   \n",
            "...          ...        ...        ...        ...              ...   \n",
            "39985      False      False      False      False            False   \n",
            "40401      False      False      False      False            False   \n",
            "40404      False      False      False      False            False   \n",
            "40806      False      False      False       True            False   \n",
            "40840      False      False      False       True             True   \n",
            "\n",
            "       day_of_week_thu  day_of_week_tue  day_of_week_wed  \n",
            "10               False            False            False  \n",
            "11               False            False            False  \n",
            "16               False            False            False  \n",
            "31               False            False            False  \n",
            "104              False            False            False  \n",
            "...                ...              ...              ...  \n",
            "39985            False             True            False  \n",
            "40401             True            False            False  \n",
            "40404             True            False            False  \n",
            "40806             True            False            False  \n",
            "40840            False            False            False  \n",
            "\n",
            "[1784 rows x 52 columns]\n",
            "\n",
            "Duplicates removed. Current shape of DataFrame: (39404, 52)\n",
            "\n",
            "No missing values found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Data Shape (After Balancing): (55690, 52)\n",
            "Testing Data Shape: (7881, 52)\n",
            "\n",
            "Class Distribution in Balanced Training Data:\n",
            "y\n",
            "0    0.5\n",
            "1    0.5\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Final DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 39404 entries, 0 to 41187\n",
            "Data columns (total 52 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   age                            39404 non-null  float64\n",
            " 1   campaign                       39404 non-null  float64\n",
            " 2   pdays                          39404 non-null  float64\n",
            " 3   previous                       39404 non-null  float64\n",
            " 4   poutcome                       39404 non-null  float64\n",
            " 5   emp.var.rate                   39404 non-null  float64\n",
            " 6   cons.price.idx                 39404 non-null  float64\n",
            " 7   cons.conf.idx                  39404 non-null  float64\n",
            " 8   euribor3m                      39404 non-null  float64\n",
            " 9   nr.employed                    39404 non-null  float64\n",
            " 10  y                              39404 non-null  int64  \n",
            " 11  job_blue-collar                39404 non-null  float64\n",
            " 12  job_entrepreneur               39404 non-null  float64\n",
            " 13  job_housemaid                  39404 non-null  float64\n",
            " 14  job_management                 39404 non-null  float64\n",
            " 15  job_retired                    39404 non-null  float64\n",
            " 16  job_self-employed              39404 non-null  float64\n",
            " 17  job_services                   39404 non-null  float64\n",
            " 18  job_student                    39404 non-null  float64\n",
            " 19  job_technician                 39404 non-null  float64\n",
            " 20  job_unemployed                 39404 non-null  float64\n",
            " 21  job_unknown                    39404 non-null  float64\n",
            " 22  marital_married                39404 non-null  float64\n",
            " 23  marital_single                 39404 non-null  float64\n",
            " 24  marital_unknown                39404 non-null  float64\n",
            " 25  education_basic.6y             39404 non-null  float64\n",
            " 26  education_basic.9y             39404 non-null  float64\n",
            " 27  education_high.school          39404 non-null  float64\n",
            " 28  education_illiterate           39404 non-null  float64\n",
            " 29  education_professional.course  39404 non-null  float64\n",
            " 30  education_university.degree    39404 non-null  float64\n",
            " 31  education_unknown              39404 non-null  float64\n",
            " 32  default_unknown                39404 non-null  float64\n",
            " 33  default_yes                    39404 non-null  float64\n",
            " 34  housing_unknown                39404 non-null  float64\n",
            " 35  housing_yes                    39404 non-null  float64\n",
            " 36  loan_unknown                   39404 non-null  float64\n",
            " 37  loan_yes                       39404 non-null  float64\n",
            " 38  contact_telephone              39404 non-null  float64\n",
            " 39  month_aug                      39404 non-null  float64\n",
            " 40  month_dec                      39404 non-null  float64\n",
            " 41  month_jul                      39404 non-null  float64\n",
            " 42  month_jun                      39404 non-null  float64\n",
            " 43  month_mar                      39404 non-null  float64\n",
            " 44  month_may                      39404 non-null  float64\n",
            " 45  month_nov                      39404 non-null  float64\n",
            " 46  month_oct                      39404 non-null  float64\n",
            " 47  month_sep                      39404 non-null  float64\n",
            " 48  day_of_week_mon                39404 non-null  float64\n",
            " 49  day_of_week_thu                39404 non-null  float64\n",
            " 50  day_of_week_tue                39404 non-null  float64\n",
            " 51  day_of_week_wed                39404 non-null  float64\n",
            "dtypes: float64(51), int64(1)\n",
            "memory usage: 15.9 MB\n",
            "\n",
            "Final DataFrame Preview:\n",
            "        age  campaign  pdays  previous  poutcome  emp.var.rate  \\\n",
            "0  0.481481       0.0    1.0       0.0       0.5        0.9375   \n",
            "1  0.493827       0.0    1.0       0.0       0.5        0.9375   \n",
            "2  0.246914       0.0    1.0       0.0       0.5        0.9375   \n",
            "3  0.283951       0.0    1.0       0.0       0.5        0.9375   \n",
            "4  0.481481       0.0    1.0       0.0       0.5        0.9375   \n",
            "\n",
            "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month_jun  \\\n",
            "0        0.698753        0.60251   0.957379     0.859735  ...        0.0   \n",
            "1        0.698753        0.60251   0.957379     0.859735  ...        0.0   \n",
            "2        0.698753        0.60251   0.957379     0.859735  ...        0.0   \n",
            "3        0.698753        0.60251   0.957379     0.859735  ...        0.0   \n",
            "4        0.698753        0.60251   0.957379     0.859735  ...        0.0   \n",
            "\n",
            "   month_mar  month_may  month_nov  month_oct  month_sep  day_of_week_mon  \\\n",
            "0        0.0        1.0        0.0        0.0        0.0              1.0   \n",
            "1        0.0        1.0        0.0        0.0        0.0              1.0   \n",
            "2        0.0        1.0        0.0        0.0        0.0              1.0   \n",
            "3        0.0        1.0        0.0        0.0        0.0              1.0   \n",
            "4        0.0        1.0        0.0        0.0        0.0              1.0   \n",
            "\n",
            "   day_of_week_thu  day_of_week_tue  day_of_week_wed  \n",
            "0              0.0              0.0              0.0  \n",
            "1              0.0              0.0              0.0  \n",
            "2              0.0              0.0              0.0  \n",
            "3              0.0              0.0              0.0  \n",
            "4              0.0              0.0              0.0  \n",
            "\n",
            "[5 rows x 52 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ensure directories exist\n",
        "output_dir = '/content/drive/My Drive/ML_CW/'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "transformed_path = output_dir + 'transformed_add.csv'\n",
        "train_data_path = output_dir + 'train_data_add.csv'\n",
        "test_data_path = output_dir + 'test_data_add.csv'\n",
        "\n",
        "try:\n",
        "    data_add.to_csv(transformed_path, index=False)\n",
        "    train_data_add.to_csv(train_data_path, index=False)\n",
        "    test_data_add.to_csv(test_data_path, index=False)\n",
        "\n",
        "    print(f\"Transformed data saved to: {transformed_path}\")\n",
        "    print(f\"Training Data saved to: {train_data_path}\")\n",
        "    print(f\"Testing Data saved to: {test_data_path}\")\n",
        "\n",
        "    if os.path.exists(transformed_path) and os.path.exists(train_data_path) and os.path.exists(test_data_path):\n",
        "        print(\"All files saved successfully.\")\n",
        "    else:\n",
        "        print(\"Error in saving files.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving files: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lQR5EcPdZjt",
        "outputId": "c7504502-1cae-4730-b88e-38bffa754026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Transformed data saved to: /content/drive/My Drive/ML_CW/transformed_add.csv\n",
            "Training Data saved to: /content/drive/My Drive/ML_CW/train_data_add.csv\n",
            "Testing Data saved to: /content/drive/My Drive/ML_CW/test_data_add.csv\n",
            "Error in saving files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# File paths for training and testing data\n",
        "train_file_path = '/content/drive/My Drive/ML_CW/train_data_add.csv'\n",
        "test_file_path = '/content/drive/My Drive/ML_CW/test_data_add.csv'\n",
        "\n",
        "# Load training and testing data\n",
        "train_data = pd.read_csv(train_file_path)\n",
        "test_data = pd.read_csv(test_file_path)\n",
        "\n",
        "X_train = train_data.drop('y', axis=1)\n",
        "y_train = train_data['y']\n",
        "\n",
        "X_test = test_data.drop('y', axis=1)\n",
        "y_test = test_data['y']\n",
        "\n",
        "# Initialize Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# fit the classifier\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluating the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "# Output to debug\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Feature Importances\n",
        "feature_importances = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': rf_classifier.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop Features:\")\n",
        "print(feature_importances.head())\n"
      ],
      "metadata": {
        "id": "Qn6yYVk_AQJl",
        "outputId": "fa7ad1c2-f54d-4645-da27-2242adb08e66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.88\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.94      6961\n",
            "           1       0.51      0.36      0.42       920\n",
            "\n",
            "    accuracy                           0.88      7881\n",
            "   macro avg       0.71      0.66      0.68      7881\n",
            "weighted avg       0.87      0.88      0.88      7881\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[6640  321]\n",
            " [ 587  333]]\n",
            "\n",
            "Top Features:\n",
            "        Feature  Importance\n",
            "8     euribor3m    0.127059\n",
            "1      campaign    0.113511\n",
            "9   nr.employed    0.086621\n",
            "0           age    0.080504\n",
            "5  emp.var.rate    0.050869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bYNdIYyFf2Qv"
      }
    }
  ]
}